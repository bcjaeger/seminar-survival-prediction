---
title: "Introduction to Machine Learning"
author: "Byron C. Jaeger"
date: "Last updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default]
    lib_dir: libs
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  
---

```{css, echo = FALSE}

.huge { font-size: 200% }
.large { font-size: 130% }
.small { font-size: 70% }

```


```{r setup, include=FALSE}

options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(
  echo=FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width=12, 
  fig.height=5.5, 
  dpi=72*5
)

library(diagram)
library(MASS)
library(tidymodels)
library(tibbleOne)
library(survival)
library(gam)
library(glue)
library(gridExtra)
library(knitr)
library(kableExtra)
library(scales)
library(widgetframe)
library(magrittr)
library(pec)
library(tidyverse)

thm  <- theme_bw() + 
  theme(
    text = element_text(size=18, face = 'bold'),
    panel.grid = element_blank()
  )

theme_set(thm)

```


# Hello! My name is Byron 

.left-column[

I like running, walking my dog, bad margaritas, Rocket League, and (of course) R.

I study <br/> machine learning, missing data, ambulatory blood pressure, and cardiovascular disease.

Also, I'm a <br/>Biostatistician!

]

.right-column[

<img src="figs/run_R_kids_markedup.png" width="100%" align="right" />

]

---
class: center
background-image: url(figs/scream_face.jpg)
background-position: 50% 70%
background-size: 30%


# Wait.

## Is this a math talk?


---
class: middle, center, inverse

# PART I

# What is Machine Learning?

---
layout: true 
class: center, middle

---

### Machine learning is well known, but common misconceptions abound...

---

### Artificial intelligence is the same thing as machine learning...?

---

### Machine learning is a type of deep learning...?

---

### Everything that involves machine learning involves a black box...?

---

### If these are wrong, what is right?

---
layout: false

# What is ML?

```{r, out.width='100%'}
include_graphics("figs/ai_ml_dl.png")
```

---
background-image: url(figs/ml_diagram.png)
background-size: 90%
background-position: 50% 50%

---
layout: true

# ML vs. Inference

---
background-image: url(figs/stats_inference.png)
background-size: 15%
background-position: 95% 5%

## Statistical Inference

- .large[Forming judgments about the parameters of a population.]

- .large[**Hypothesis** driven (exploring is frowned upon)]

- .large[End-point of analysis is **knowledge**]

--

### Inference $\Rightarrow$ guidelines $\Rightarrow$ decisions $\Rightarrow$ outcomes


---
background-image: url(figs/data_mining.jpg)
background-size: 20%
background-position: 95% 5%

## Supervised Learning 

- .large[Forming a prediction function to engage with uncertainty.]

- .large[**Performance** driven (exploring is necessary)]

- .large[End-point of analysis is a **prediction function**]

--

### Predictions $\Rightarrow$ decisions $\Rightarrow$ outcomes

---
layout: false
class: middle, center

```{r, out.width='90%'}
include_graphics("figs/data_analysis_flow.jpg")
```

---
class: middle, center

# [Data product demo](https://bcjaeger.shinyapps.io/DPE4NHTN_WebApp/)

---
class: middle, center, inverse

# PART II

# Core Principles of Machine Learning

---
class: middle, center

# Core principal 1:

# Bias-variance tradeoff

---
layout: true
background-image: url(figs/esl.jpg)
background-position: 96% 4%
background-size: 18%

# Core Principles of ML

### Bias-variance tradeoff


---


 You may recognize the terms bias and variance if you have some experience with statistics.

--

- **Bias:** expected difference between observed and predicted values (in derivation data)

- **Variance:** measure of dispersion in the distribution of predicted values.

These are correct (but not helpful) definitions.

---

You may recognize the terms bias and variance if you have some experience with statistics.

- **Bias:** how well does a model predict its derivation data?

- **Variance:** how complex is the model?

These are incorrect (but helpful) definitions.

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

```{r}

nsubs=25
ntst=25000
set.seed(3)
x=runif(nsubs,0,10)
ggdat=data.frame(y=x*(3+sin(pi*x/3))+rnorm(nsubs,sd=x),x=x)
xgrid=seq(min(x),max(x),length.out=100)
truth=data.frame(x=xgrid)%>%mutate(y=x*(3+sin(pi*x/3)))

ggplot(ggdat,aes(x=x,y=y))+geom_point(size=3)+
  labs(title='Simulated Data',x='X-value',y='Y-value')

```

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

```{r}

ggplot(ggdat,aes(x=x,y=y))+geom_point(size=3)+
  labs(title='Simulated Data',x='X-value',y='Y-value')+
  geom_line(data=truth,aes(x=x,y=y),color='red',linetype=2)

your_data <- as_tibble(ggdat)

spars = seq(1.0, 0.3, length.out = 15)
mdl_cmplx = 1:length(spars)
grid_plots = vector(mode = 'list', length = length(spars))
my_data = truth %>% 
  mutate(y = y + rnorm(length(xgrid), sd = xgrid)) %>% 
  as_tibble()

sqr <- function(x)
  x ^ 2


```

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** I give you a dataset with 25 observations:
```{r, eval = FALSE, echo=TRUE}
print(your_data)
```
]

.pull-right[
```{r}
print(your_data)
```
]


---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** I'm keeping a dataset away from you. It has `r nrow(my_data)` observations:
```{r, eval = FALSE, echo=TRUE}
print(my_data)
```
]

.pull-right[
```{r}
print(my_data)
```
]

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** I'll give you my $X$ values, and then you'll try to predict what my $Y$ values are 
```{r, eval = FALSE, echo=TRUE}
select(my_data, x)
```
]

.pull-right[
```{r}
select(my_data, x)
```
]

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** Let's say your predictions are the mean of your observed $Y$ values, $$\widehat{Y} = \frac{1}{`r nrow(your_data)`}\sum_{i=1}^{`r nrow(your_data)`} (Y_i^{\text{(your data)}})^2$$.

```{r, eval = FALSE, echo=TRUE}

yobs <- my_data$y
yobs[1:10]

yhat <- mean(your_data$y)
yhat

```
]

.pull-right[
```{r}

yobs <- my_data$y
matrix(yobs[1:10], ncol=1)

yhat <- mean(your_data$y)
yhat

```
]

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** I will calculate how accurate your predictions are by computing $$\sqrt{\frac{1}{`r nrow(my_data)`}\sum_{i=1}^{`r nrow(my_data)`} (Y_i^{\text{(my data)}}-\widehat{Y})^2}$$
```{r, eval = FALSE, echo=TRUE}

# squared differences
sqr_diffs <- (yobs - yhat)^2
# mean squared error
sqrt(mean(sqr_diffs))

```
]

.pull-right[
```{r}

sqr_diffs <- (yobs - yhat)^2
sqrt(mean(sqr_diffs))

```
]

---

**Example:** Suppose data are $\mathcal{D} = (Y,X)$, where $Y = f(X)$ and $f$ is an unknown function. 

.pull-left[
**Workflow:** That's not a great mean squared error. Maybe we can do better if we develop a function $\widehat{f}(X)$ that predicts $Y$.

```{r, eval = FALSE, echo=TRUE}

model <- ???

```
]

.pull-right[
```{r}

sqrt(mean(sqr_diffs))

```
]

---

```{r, cache=TRUE}


mprf=data.frame(
  cmp=mdl_cmplx,
  trn=0,
  tst=0
)

i=1

for(i in mdl_cmplx){
  
  m=gam(y~s(x,spar=spars[i]),data=ggdat)
  ggdat$prd=predict(m)
  my_data$prd=predict(m,newdata=my_data)
  
  p1=ggplot(ggdat,aes(x=x,y=y))+geom_point(size=3)+
    geom_line(data=my_data,aes(x=x,y=prd),col='blue')+
    geom_line(data=truth,aes(x=x,y=y),linetype=2,col='red')+
    labs(title=paste("derivation data error:",format(round(sqrt(mean(sqr(
      ggdat$y-ggdat$prd))),3),nsmall=3), '\nModel AIC', format(round(
        AIC(m),2),nsmall=2)))
  
  mprf[i,c('trn','tst')]<-c(
    sqrt(mean(sqr(ggdat$y-ggdat$prd))),
    sqrt(mean(sqr(my_data$y-my_data$prd)))
  )
  
  p2=ggplot(mprf%>%
              tidyr::gather(variable,value,-cmp)%>%
              dplyr::filter(value>0)%>%
              dplyr::mutate(cmp=cmp-1),
            aes(x=cmp,y=value,col=variable))+
    geom_point(size=3)+
    thm + theme(legend.position='') + 
    scale_color_brewer(palette='Dark2')+
    labs(y='Model Error',x='Model Complexity',
         title='derivation error (blue) and \nvalidation error (orange)')
  
  if(i>1) p2=p2+geom_line()

  grid_plots[[i]]=arrangeGrob(p1,p2,nrow=1)

}

simulated_data = ggdat

```

```{r, echo=TRUE, eval=FALSE}
# spar = 1 => least complex spline
model <- gam(y ~ s(x, spar=1), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[1]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.95 => a little more wiggle room
model <- gam(y ~ s(x, spar=0.95), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[2]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.90 => a little more wiggle room
model <- gam(y ~ s(x, spar=0.90), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[3]]) 
```
---

```{r, echo=TRUE, eval=FALSE}
# spar = 0.85 => more 
model <- gam(y ~ s(x, spar=0.85), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[4]]) 
```
---

```{r, echo=TRUE, eval=FALSE}
# spar = 0.80 => more 
model <- gam(y ~ s(x, spar=0.80), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[5]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.75 => more 
model <- gam(y ~ s(x, spar=0.75), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[6]]) 
```
---

```{r, echo=TRUE, eval=FALSE}
# spar = 0.70 => more
model <- gam(y ~ s(x, spar=0.70), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[7]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.65 => more (too much?)
model <- gam(y ~ s(x, spar=0.65), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[8]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.60 => more (too much?)
model <- gam(y ~ s(x, spar=0.60), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[9]]) 
```
---

```{r, echo=TRUE, eval=FALSE}
# spar = 0.55 => more (too much?)
model <- gam(y ~ s(x, spar=0.55), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[10]]) 
```
---

```{r, echo=TRUE, eval=FALSE}
# spar = 0.50 => more (too too much??)
model <- gam(y ~ s(x, spar=0.50), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[11]]) 
```
---
```{r, echo=TRUE, eval=FALSE}
# spar = 0.45 => more (much too much!!)
model <- gam(y ~ s(x, spar=0.45), data=simulated_data)
```

```{r} 
grid.arrange(grid_plots[[12]]) 
```

---
layout: false
background-image: url(gifs/cat_snow_gif.gif)
background-position: 50% 60%
background-size: 50%

# In summary...

---
class: inverse, center, middle

# Case Study

---
layout: true
background-image: url(figs/intermacs_logo.jpg)
background-position: 97% 3%
background-size: 15%

# Case Study

### INTERMACS

---

**What is it?**

- Interagency Registry for Mechanically Assisted Circulatory Support

- Contains data from patients with advanced heart failure receiving mechanical circulatory support (MCS). 

---

**Why use it?**

- Patients who elect to receive MCS are at risk for a number of adverse events related to the device, such as death, stroke, malfunction, and infection.

- Targeted medical intervention should be directed to patients at high risk for events. 
    
- But...**who** is at risk? and **what** are they at risk for?

---
layout: false
background-image: url(figs/intermacs_slides/Slide1.PNG)
background-position: 20% 50%
background-size: 120%

# Case Study

### INTERMACS

---
background-image: url(figs/intermacs_slides/Slide2.PNG)
background-position: 20% 50%
background-size: 120%

# Case Study

### INTERMACS

---
background-image: url(figs/intermacs_slides/Slide3.PNG)
background-position: 20% 50%
background-size: 120%

# Case Study

### INTERMACS

---

```{r, include = FALSE}


mcs <- read_csv('data/dead_M0_25MD.csv',guess_max = 20000) %>% 
  mutate(
    #time = time - 1/4,
    surv_1yr = case_when(
    time < 1 & status == 1 ~ "No", 
    time < 1 & status == 0 ~ "Censored",
    TRUE ~ "Yes"
    ),
    surv_1yr = factor(
      x = surv_1yr,
      levels = c("Yes", "Censored", "No")
    ),
    m0_impl_yr = factor(m0_impl_yr)
  ) %>% 
  mutate_if(is.character, as.factor) 

```

```{r, results='asis'}

tb1 <- mcs %>% 
  select_labelled(
    surv_1yr = "Survived 1 year",
    m0_age_deident = "Age",
    m0_race_white = 'White',
    m0_impl_yr = "Implant year"
  ) %>% 
  set_variable_units(m0_age_deident = 'years') %>% 
  tibble_one(
    formula = ~ . | surv_1yr, 
    include_freq = TRUE,
  ) %>% 
  to_kable(caption = 'Table 1: INTERMACS patient characteristics') %>% 
  kable_styling()

print(tb1)

```


---
class: center, middle

# Core principal 2:

# External validation

---
layout: true
background-image: url(figs/text_trio.jpg)
background-position: 96% 4%
background-size: 25%

# Core Principles of ML

---

### External validation

**Why is this a core principle?** 

Anyone can predict what they already know. The value of prediction is tied to anticipating *external* information.

**What is external information?**

Data that comes from a different 

- place and / or time.

- research organization and / or team

- instrument

- population

than the derivation data.

---

### External validation with INTERMACS

**Problem:** Develop a function $\widehat{f}(t):$ `r icon::fa_user_circle()` $\rightarrow (0,1]$ 

- $\widehat{f}(t)$ predicts risk for *mortality* at or before $t$.

- $t$ ranges from 1 week to 1 years post MCS surgery.

- `r icon::fa_user_circle()` is **new** patient data collected

    + prior to MCS surgery at a pre-implant visit (variables with prefix `m0`)
    
    + 1 week after MCS surgery at a follow-up visit (variables with prefix `m0_25`)

--

**Question:** How do we know $\widehat{f}(t)$ is accurate?

- Bias-variace tradeoff $\Rightarrow$ we need a relevant set of **new** data to test $\widehat{f}(t)$.

---
layout: false

```{r}

tb1 %>% 
  row_spec(12:13, bold = T, color = "white", background = "red")


```

---
layout: false

```{r}

tb1 %>% 
  row_spec(8:11, bold = T, color = "white", background = "green")


```

---
layout: true
background-image: url(figs/esl.jpg)
background-position: 96% 4%
background-size: 18%

# Core Principles of ML

---

### External validation with INTERMACS

**Problem:** Develop a function $\widehat{f}(t):$ `r icon::fa_user_circle()` $\rightarrow (0,1]$ 

- $\widehat{f}(t)$ predicts risk for *mortality* at or before $t$.

- $t$ ranges from 1 week to 1 years post MCS surgery.

- `r icon::fa_user_circle()` is **new** patient data collected

    + prior to MCS surgery at a pre-implant visit (variables with prefix `m0`)
    
    + 1 week after MCS surgery at a follow-up visit (variables with prefix `m0_25`)

**Question:** How do we know $\widehat{f}(t)$ is accurate?

- Relevant set of **new** data to test $\widehat{f}(t)$: INTERMACS **data from 2016-2017**. `r icon::fa_check(color = 'green')`

- Given $t$, validation outcomes $\in \left\{0, 1\right\} \Rightarrow$ compare observed outcome to $\widehat{f}(t)$

---
layout: true
background-image: url(figs/scream_face.jpg)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML


---

### Brier Score

The **Brier score** of a predicted probability $$\widehat{f}(t) \in (0, 1]$$ for an observed event $$Y(t) \in \left\{ 0, 1 \right\}$$ is $$\left( \widehat{f}(t) -  Y(t) \right)^{2}.$$

**Examples** 

- If $\widehat{f}(t) = 0.10$ and $Y=0$, the **Brier score** is $(0.10 - 0.00)^{2} = 0.01$.

- If $\widehat{f}(t) = 0.50$, the **Brier score** is always 0.25. Why?

---

### Brier Score at a given time


```{r}

outcome <- tibble(time = seq(1, 24, length.out = 1000)) %>% 
  mutate(event = as.numeric(time >= 12))

prediction <- outcome %>% 
  mutate(event = exp(time-12) / (1+exp(time-12)))

p1 <- ggplot(outcome, aes(x=time, y=event)) +
  geom_line(color = 'grey', linetype = 2)

p2 <- p1 +
  geom_line(data=prediction, color = 'red', linetype = 1)

p1 + 
  geom_curve(
  x = 12,
  y = 0.20,
  xend = 20, 
  yend = .50,
  color = 'gray',
  linetype = 5
) + 
  annotate(
    geom = 'text',
    label = 'Observed event \nstatus',
    x = 20, 
    y = 0.60,
    size = 6
  )

```

---

### Brier Score at a given time

```{r}

p2 + geom_curve(
  x = 5,
  y = 0.50,
  xend=prediction$time[400], 
  yend=prediction$event[400],
  color = 'red',
  linetype = 5
) + 
  annotate(
    geom = 'text',
    label = 'Predicted event \nprobability',
    x = 5, 
    y = 0.60,
    size = 6
  )

```


---

### Brier Score at a given time

```{r}

p2 + geom_segment(
  x = prediction$time[400],
  y = 0,
  xend = prediction$time[400], 
  yend = prediction$event[400],
  color = 'black',
  linetype = 5
) + 
  geom_point(
    x = prediction$time[400], 
    y = prediction$event[400]
  ) +
  annotate(
    geom = 'text',
    label = glue('Brier score \nat t = {round(prediction$time[400],1)}'),
    x = 8, 
    y = 0.2,
    size = 6
  )

```

---

### Brier Score at another given time


```{r}

p2 + geom_segment(
  x = prediction$time[600],
  y = 1,
  xend = prediction$time[600], 
  yend = prediction$event[600],
  color = 'black',
  linetype = 5
) + 
  geom_point(
    x = prediction$time[600], 
    y = prediction$event[600]
  ) +
  annotate(
    geom = 'text',
    label = glue('Brier score \nat t = {round(prediction$time[600],1)}'),
    x = 17, 
    y = 0.83,
    size = 6
  )

```

---

### Brier Score at many given times


```{r}

p3 = p2 

for(i in seq(300, 700, by = 25)){
  
  p3 = p3 + geom_segment(
    x = prediction$time[i],
    y = if(i >= 500) 1 else 0,
    xend = prediction$time[i], 
    yend = prediction$event[i],
    color = 'black',
    linetype = 5
  ) + 
    geom_point(
      x = prediction$time[i], 
      y = prediction$event[i]
    )
  
}

p3 + 
  annotate(
    geom = 'text',
    label = 'Lots of Brier scores!',
    x = 17, 
    y = 0.50,
    size = 6
  )

```

---

### Integrated Brier Score

**Why?**

Integrating the Brier score over a range of times summarizes overall prediction accuracy. 

**How?**

Computing Brier scores at all potential times for one observation, i.e.,

$$\text{ibs}(T) = \frac{1}{\text{T}} \int_{0}^{T} \left(\widehat{f}(t) - Y(t) \right)^{2} dt$$

For a validation sample with $N$ observations, 

$$\text{IBS}(T) = \frac{1}{N} \sum_{i=1}^N \text{ibs}_i(T)$$



---

### Scaled Brier Score

**Why?**

- IBS = 0 $\Rightarrow$ perfect model. Great! What if IBS = 0.05?

- IBS = 0.25 $\Rightarrow$ non-informative model, if the outcome has 50% prevalence.

- Max IBS is determined by the prevalence of the outcome.

**How?** 

If the outcome is present in 10% of the population, then the max IBS is 

$$(0.1) \cdot (1–0.1)^{2} + (1–0.1) \cdot (0.1)^{2} = 0.090$$ 

So if our model gets an IBS of 0.05, we could scale it to be $\leq 1$ using 

$$1 - \frac{0.05}{0.090} = 0.444$$

---

layout: true
background-image: url(figs/esl.jpg)
background-position: 96% 4%
background-size: 18%

# Core Principles of ML

---

### External validation with INTERMACS

**Problem:** Develop a function $\widehat{f}(t):$ `r icon::fa_user_circle()` $\rightarrow (0,1]$ 

- $\widehat{f}(t)$ predicts risk for *mortality* at or before $t$.

- $t$ ranges from 1 week to 1 years post MCS surgery.

- `r icon::fa_user_circle()` is **new** patient data collected

    + prior to MCS surgery at a pre-implant visit (variables with prefix `m0`)
    
    + 1 week after MCS surgery at a follow-up visit (variables with prefix `m0_25`)

**Question:** How do we know $\widehat{f}(t)$ is accurate?

- Relevant set of **new** data to test $\widehat{f}(t)$: INTERMACS **data from 2016-2017**. `r icon::fa_check(color = 'green')`

- Compare observed outcome to $\widehat{f}(t)$ using the **scaled integrated Brier score**. `r icon::fa_check(color = 'green')`

```{r}

mcs$surv_1yr = NULL
mcs$m0_impl_yr %<>% as.character() %>% as.numeric()

```

---
layout: true

# Case study

---
background-image: url(hex_stickers/PNG/dplyr.png)
background-position: 95% 2.5%
background-size: 13%

### ML workflow for INTERMACS

Make the derivation / validation sets

.pull-left[

```{r, echo = TRUE, eval = FALSE}

derivation <- mcs %>% 
  filter(
    m0_impl_yr >= 2012,
    m0_impl_yr <= 2015
  ) %>% 
  select(-m0_impl_yr)

validation <- mcs %>% 
  filter(
    m0_impl_yr >= 2016
  ) %>% 
  select(-m0_impl_yr)

dim(derivation)

dim(validation)

dim(mcs)

```


]

.pull-right[

```{r, echo = FALSE, eval = TRUE}

derivation <- mcs %>% 
  filter(
    m0_impl_yr >= 2012,
    m0_impl_yr <= 2015
  ) %>% 
  select(-m0_impl_yr)

validation <- mcs %>% 
  filter(m0_impl_yr >= 2016) %>% 
  select(-m0_impl_yr)

dim(derivation)

dim(validation)

dim(mcs)
```


]

---
background-image: url(hex_stickers/PNG/recipes.png)
background-position: 95% 2.5%
background-size: 13%

### ML workflow for INTERMACS

The R package, `recipes`, lets you specify step-by-step instructions for data pre-processing.

The pre-processing steps applied here:

1. impute continuous variables to the mean,

2. impute categorical variables to the mode.

```{r, echo = TRUE}

reci <- recipe(
  formula = time + status ~ ., 
  data = derivation
) %>% 
  step_meanimpute(all_numeric()) %>% 
  step_modeimpute(all_nominal()) %>% 
  prep()

```

---
background-image: url(hex_stickers/PNG/recipes.png)
background-position: 95% 2.5%
background-size: 13%

### ML workflow for INTERMACS

The R package, `recipes`, lets you specify step-by-step instructions for data pre-processing.

```{r}

reci

```

---
background-image: url(hex_stickers/PNG/recipes.png)
background-position: 95% 2.5%
background-size: 13%

### ML workflow for INTERMACS

`.derivation` and `.validation` represent pre-processed versions of `derivation` and `validation`. (In this case, pre-processed = imputed).

```{r, echo = TRUE}

# pre-processed derivation / validation data
.derivation <- juice(reci)
.validation <- bake(reci, new_data = validation)

dim(na.omit(derivation))
dim(na.omit(.derivation))

```


---
background-image: url(hex_stickers/PNG/recipes.png)
background-position: 95% 2.5%
background-size: 13%

### ML workflow for INTERMACS

`btimes` is a sequence comprising all of the times we will evaluate predicted risk for mortality.

```{r, echo = TRUE}

# times to evaluate predictions
btimes <- seq(min(validation$time), 12, length.out = 500)

btimes[1:10]

```

---
background-image: url(figs/intermacs_model_table.png)
background-position: 50% 70%
background-size: 80%

---
background-image: url(figs/intermacs_model_table_edited.jpg)
background-position: 50% 70%
background-size: 80%

---
background-image: url(figs/intermacs_logo.jpg)
background-position: 97% 3%
background-size: 15%

### ML workflow for INTERMACS

```{r}

ref_data <- list(
  derivation = .derivation,
  validation = .validation   
) %>% 
  map(
    .f = function(df){
      mutate(
        df, 
        ccs = m0_px_profile == '1 Critical Cardiogenic Shock',
        ccs = as.numeric(ccs),
        current_smoker = if_else(
          m0_cc_curr_smoking_m == "Yes" | 
            m0_cc2_curr_smoking_m == "Yes",
          true = 1, 
          false = 0
        ),
        periph_vasc = if_else(
          m0_cc_periph_vasc_disease_m == "Yes" | 
            m0_cc2_periph_vasc_disease_m == "Yes",
          true = 1, 
          false = 0
        ),
        non_comp = if_else(
          m0_cc2_rptd_non_compliance_m == 'Yes' | 
            m0_cc_rptd_non_compliance_m == 'Yes',
          true = 1, 
          false = 0
        ),
        age2 = m0_age_deident^2,
        bmi = m0_wgt_kg / (m0_hgt_cm/100)^2
      ) %>%
        select(
          time,
          status,
          everything()
          # age2,
          # bmi,
          # ccs,
          # periph_vasc,
          # current_smoker,
          # non_comp,
          # m0_intervention_48_hrs_dialysis,
          # m0_prev_cardiac_oper_none,
          # m0_ra_pres,
          # m0_cv_pres,
          # m0_bili_total_mg_dl,
          # m0_lvedd,
          # m0_bun_mg_dl,
          # m0_albumin_g_dl,
          # m0_25_ra_pres,
          # m0_25_cv_pres,
          # m0_25_bili_total_mg_dl,
          # m0_25_lvedd,
          # m0_25_bun_mg_dl,
          # m0_25_albumin_g_dl
        ) %>%
        mutate_if(is.character, as.factor)
    }
  )

.derivation <- ref_data$derivation
.validation <- ref_data$validation

```


`frm_1` is a model formula comprising variables listed in the early hazard phase.

```{r, echo = TRUE}

# expert model formula 

frm_1 <- Surv(time, status) ~ 
  age2 + # age squared 
  ccs +  # critical cardiogenic shock
  m0_cv_pres + # central venous pressure
  m0_bili_total_mg_dl + # bilirubin
  m0_lvedd + # left ventricular end-diastolic dimension
  m0_intervention_48_hrs_dialysis + # prior to surgery
  m0_bun_mg_dl + # blood urea nitrogen
  m0_albumin_g_dl + # urinary albumin
  m0_prev_cardiac_oper_none # no previous heart operation

```

---

background-image: url(hex_stickers/PNG/pipe.png)
background-position: 95% 2.5%
background-size: 13%


```{r}

ibs_scale <- function(
  object,
  newdata,
  eval_times,
  time = 'time',
  status = 'status'
) {
  
  formula <- glue("Surv({time}, {status}) ~ 1")
  
  .dots <- list(
    object = object,
    formula = as.formula(formula),
    data = newdata[, c(time, status)],
    times = eval_times,
    start = eval_times[1],
    maxtime = eval_times[length(eval_times)],
    exact = FALSE
  )
  
  BS <- suppressMessages(do.call(pec, .dots)) 
  
  IBS <- as.numeric(ibs(BS))
  
  1 - IBS[-1] / IBS[1]
  
}

```

ML workflow using `%>%` (read as **then**).

1. Fit the Cox Proportional Hazards (`coxph`) model, **then**

2. using the `coxph` model, predict survival probabilities in the `.validation` data, **then**

3. using the predicted survival probabilities at all of the `btimes`, compute the IBS.

```{r, echo = TRUE}

ibs_cph_1 <- coxph(frm_1, data = .derivation, x = TRUE) %>% 
  predictSurvProb(newdata = .validation, times = btimes) %>% 
  ibs_scale(newdata = .validation, eval_times = btimes)

ibs_cph_1

```

---

background-image: url(hex_stickers/PNG/pipe.png)
background-position: 95% 2.5%
background-size: 13%


What if we use week 1 follow-up data instead of pre-implant data?

```{r, echo = TRUE}

frm_2 <- Surv(time, status) ~ 
  age2 + # age squared 
  ccs +  # critical cardiogenic shock
  m0_25_cv_pres + # central venous pressure
  m0_25_bili_total_mg_dl + # bilirubin
  m0_25_lvedd + # left ventricular end-diastolic dimension
  m0_intervention_48_hrs_dialysis + # prior to surgery
  m0_25_bun_mg_dl + # blood urea nitrogen
  m0_25_albumin_g_dl + # urinary albumin
  m0_prev_cardiac_oper_none # no previous heart operation


ibs_cph_2 <- coxph(frm_2, data = .derivation, x = TRUE) %>% 
  predictSurvProb(newdata = .validation, times = btimes) %>% 
  ibs_scale(newdata = .validation, eval_times = btimes)

ibs_cph_2


```

---
background-image: url(hex_stickers/PNG/purrr.png)
background-position: 95% 2.5%
background-size: 13%

We can clean this iterative code up with `purrr::map()`

```{r, warning=FALSE, echo = TRUE}

ibs_vals <- list(
  `Pre-implant data` = frm_1,
  `Week 1 follow-up data` = frm_2
) %>% 
  map_dbl(
    .f = ~ coxph(.x, data = .derivation, x = TRUE) %>% 
      predictSurvProb(newdata = .validation, times = btimes) %>% 
      ibs_scale(newdata = .validation, eval_times = btimes)
  )

ibs_vals

```

---

background-image: url(hex_stickers/PNG/knitr.png)
background-position: 95% 2.5%
background-size: 13%

And clean up the presentation with `knitr::kable()` + `kableExtra`

<br/>

```{r}

cap <- "Table 2: Validation of three models using 2016-2017 INTERMACS data"

enframe(ibs_vals) %>% 
  mutate(perc_impr = round(100 * (value / value[1] - 1))) %>% 
  kable(
    caption = cap,
    digits = 3,
    col.names = c('Model', 'Scaled Brier', "% Improvement")
  ) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE)

```

---
layout: true
class: center, middle

---

# Just a second

---

## Should we really impute missing values using mean/mode?

---

## Should we be using proportional hazards?

---

## What happened to the other 500-ish variables?

---

## Is this the best (scaled & integrated) Brier score we can get?

---
layout: false
class: center, middle

# Core principal 3:

# Modeling algorithms

---
layout: true 
background-image: url(hex_stickers/PNG/tidymodels.png)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML

### Modeling algorithms

**Definition**

Think about the steps taken to develop a prediction function, $\widehat{f}$. 

That's the ad-hoc modeling algorithm definition. More formally, there are phases: 

---

- **Data pre-processing**

    + Check validity of the data, 
    + handle missing values (e.g., impute / discard), 
    + handle factor levels (e.g., collapse / combine), 
    + scale/center continuous variables, 
    + create new predictor variables, 
    + handle outliers, 
    + and much more.
    
---

- **Model development**

    + Select modeling procedure,
    + Select tuning parameters,
    + Select predictors,
    + Fit the model(s)

    
---
layout: false
background-image: url(hex_stickers/PNG/tidymodels.png)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML

### Modeling algorithms

Let's focus on the **model development** phase. Our initial approach used 

- a traditional statistical modeling procedure (`coxph`)

- no tuning parameters

- nine predictor variables selected by experts

Let's evaluate an alternate approach that uses 

- a stepwise implementation of `coxph`

- one tuning parameter indicating the max number of steps: nine

- nine (or less) predictor variables selected from about 500 candidates.

---
background-image: url(figs/intermacs_logo.jpg)
background-position: 97% 3%
background-size: 15%

# Core Principles of ML

### Stepwise selection with INTERMACS

```{r, eval = FALSE, echo = TRUE}

# pull x variables out of recipe
xnames <- reci$var_info %>% 
  filter(role == 'predictor') %>% 
  pull(variable)

# create full model formula (i.e., all predictors)
full <- glue(
  "Surv(time, status) ~ {glue_collapse(xnames, sep = '+')}"
)

```

---
background-image: url(figs/intermacs_logo.jpg)
background-position: 97% 3%
background-size: 15%

# Core Principles of ML

### Stepwise selection with INTERMACS

```{r, eval = FALSE, echo = TRUE}

# fit stepwise model
step_mdl <- stepAIC(
  object = coxph(Surv(time, status) ~ 1, data = .derivation),
  scope = as.formula(full),
  direction = 'both',
  steps = 9,
  trace = 0
)

# Extract the formula that was identified 
frm_3 <- step_mdl$formula

```

---
background-image: url(hex_stickers/PNG/purrr.png)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML

### Stepwise selection with INTERMACS

Now we just add `frm_3` to our `purrr::map()` code.

```{r}

frm_3 <- read_rds('data/frm_3.rds')

```

```{r, echo = TRUE}

ibs_vals <- list(
  `Pre-implant data` = frm_1,
  `Week 1 follow-up data` = frm_2,
  `Forward selection (pre-implant + week 1)` = frm_3
) %>% 
  map_dbl(
    .f = ~ coxph(.x, data = .derivation, x = TRUE) %>% 
      predictSurvProb(newdata = .validation, times = btimes) %>% 
      ibs_scale(newdata = .validation, eval_times = btimes)
  )

```

---

# Core Principles of ML

### Variables selected

```{r}

list(
  `Pre-implant data` = frm_1,
  `Week 1 follow-up data` = frm_2,
  `Forward selection` = frm_3
) %>%
  map(all.vars) %>%
  enframe() %>%
  unnest_longer(col = value) %>%
  filter(value != 'status', value != 'time') %>%
  pivot_wider(
    names_from = name,
    values_from = value,
    values_fn = list(value = list)
  ) %>%
  unnest(
    cols = c(
      `Pre-implant data`,
      `Week 1 follow-up data`,
      `Forward selection`
    )
  ) %>% 
  kable(align = c('ccc')) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(header = c("Expert formulas" = 2, " " = 1))

```

---
background-image: url(hex_stickers/PNG/knitr.png)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML

### Stepwise selection with INTERMACS

```{r}

cap <- "Table 3: Validation of three models using 2016-2017 INTERMACS data"

enframe(ibs_vals) %>% 
  mutate(perc_impr = round(100 * (value / value[1] - 1))) %>% 
  kable(
    caption = cap,
    digits = 3,
    col.names = c('Model', 'Scaled Brier', "% Improvement")
  ) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE)

```

<br/>

*wow, that's not bad*.

<br/>

**Question** How do we know if it was optimal to take nine steps?

---
class: center, middle

# Core principal 4:

# Resampling

---
layout: true
background-image: url(hex_stickers/PNG/rsample.png)
background-position: 95% 2.5%
background-size: 13%

# Core Principles of ML

---

### Resampling

**Why is this a core principle?**

Resampling allows analysts to simulate the development and external validation of a prediction equation using a specific modeling algorithm.

**What is resampling?**

We will talk about two types of resampling here:

1. *Monte-Carlo cross-validation*: Repeatedly split an initial dataset into training/testing sets

2. *K-fold cross-validation*: Partitioning an initial dataset into folds, then letting each fold serve as a testing set while the remaining folds form a training set.

Note: CV = cross-validation from here on out.

---

### Monte-Carlo CV

Randomly select a set of training data (blue rows) from the derivation data.

```{r}

par(mar = c(1, 1, 1, 1)/10, mfrow = c(1, 1))

nsubs=8
trn_col="skyblue"
tst_col="grey70"

trn=sample(nsubs, round(nsubs/2))
ntrn=length(trn)
cols=rep(tst_col,nsubs)
cols[trn]=trn_col

plotmat(matrix(nrow = nsubs, ncol = nsubs, byrow = TRUE, data = 0), 
  pos = rep(1,nsubs), name = paste("Participant", 1:nsubs), 
  lwd = 1, box.lwd = 1, box.cex = 1.5, box.size = 0.3,
  box.type = "rect", box.prop = 0.075, shadow.size=0.002,
  box.col=cols)

```

---

### Monte-Carlo CV

Use the training data to develop one prediction rule per modeling algorithm. 

```{r}

par(mar = c(1, 1, 1, 1)/10, mfrow = c(1, 1))

mdl_col='green'
prd_col='violet'

yvals=seq(0.20,0.80,length.out=ntrn)


pos=map(yvals,~c(0.20,.))%>%
  reduce(rbind)%>%rbind(c(0.50,0.25),
    c(0.50,0.75),
    c(0.80,0.25),
    c(0.80,0.75))

M <- matrix(nrow = ntrn+4, 
  ncol = ntrn+4, 
  byrow = TRUE, data = 0)

M[ntrn+1:2,1:ntrn]=1
M[8,6]=1
M[7,5]=1

C=M
C[ntrn+1,1:ntrn]=0.07
C[ntrn+2,1:ntrn]=-0.07
C[8,6]=0
C[7,5]=0


plotmat(M, pos = pos, 
  box.col = c(rep(trn_col, ntrn),rep(mdl_col,2),rep(prd_col,2)),
  name = c(paste("Participant", sort(trn, decreasing = T)),
    paste('Modeling \nAlgorithm',2:1), 
    paste('Prediction \nRule',2:1)),
  lwd = 1, box.lwd = 1, box.cex = 1.5, 
  box.size = c(rep(0.1,ntrn),rep(0.1,2),rep(0.1,2)),
  box.type = c(rep("rect",ntrn),rep("ellipse",2),rep("square",2)), 
  box.prop = c(rep(0.3,ntrn),rep(1,2),rep(0.5,2)), 
  shadow.size=0.002,dtext=1000, curve=C)

```

---

### Monte-Carlo CV

Apply each prediction rule to the testing data, creating a set of predictions for each. 

```{r}

par(mar = c(1, 1, 1, 1), mfrow = c(1, 1))

tst=setdiff(1:nsubs,trn)
ntst=length(tst)

p1=map(yvals,~c(0.20,.))%>%reduce(rbind)
p2=c(0.50,0.50)
p3=map(yvals,~c(0.80,.))%>%reduce(rbind)

pos=rbind(p1,p2,p3)

M <- matrix(nrow = 2*ntst+1, 
  ncol = 2*ntst+1, 
  byrow = TRUE, data = 0)

M[ntst+1,1:ntst]=1; M[(ntst+2):nrow(M),ntst+1]=1; 

C=M; C[ntst+2, ntst+1]=0
C[ntst+1,1:ntst]=seq(-0.06, 0.06, length.out=ntst)
C[(ntst+2):nrow(C),ntst+1]=0

set.seed(329)

prds=round(runif(ntst),2)

outs=rbinom(ntst,prob = 0.5,size=1)

dtbl=data.frame(cbind(prds=rev(prds),outs=outs))%>%
  mutate(diff=prds-outs,sqdf=diff^2)


plotmat(M, pos = pos, 
  box.col = c(rep(tst_col, ntst),prd_col,
    rep(tst_col, ntst)),
  name = c(paste("Participant", sort(tst, decreasing = T)),
    'Prediction \nRule',
    paste("P(Mortality) =", format(prds,nsmall=2))),
  lwd = 1, box.lwd = 1, box.cex = 1.5, 
  box.size = c(rep(0.11,ntrn),0.1),
  box.type = c(rep("rect",ntst),"square"), 
  box.prop = c(rep(0.3,ntst),1), 
  shadow.size=0.002, curve=C,dtext=1000)

```

---

### Monte-Carlo CV

Evaluate each set of predictions

```{r}

dtbl%>%
  set_names(
    c("P(Mortality)","Mortality",
      "Difference","Squared Difference")
  ) %>% 
  kable(
    align=c('c','c','c','c')
  ) %>%
  kable_styling(
    position = "center", 
    bootstrap_options = c("striped", "hover"),
    full_width = TRUE
  ) 


```

$$\text{Brier Score} = \frac{1}{N} \sum_{i=1}^N (\widehat{f}(x_i)-y_i)^2 = \frac{`r paste(format(round(dtbl$sqdf,2),nsmall=2),collapse=" + ")`}{`r ntst`} = `r format(round(mean(dtbl$sqdf),2),nsmall=2)`$$

---
layout: false
class: middle, center

# Resampling diagrams

---
class: middle, center

```{r, fig.height=8, fig.width=10, fig.align='center'}

par(mar = c(1, 1, 1, 1)/10, mfrow = c(1, 1))

trn_col="burlywood"
tst_col="antiquewhite"

#xvals=c(0.125,0.325,0.725)
xvals=c(0.12,0.78)
yvals = c(0.75, 0.55, 0.35, 0.10)

step1=paste(
  'Randomly',
  'split the',
  'derivation',
  'data into',
  'a training', 
  'set and a',
  'test set',
  sep=' \n')

step2 = paste( 
  'Apply each candidate modeling',
  'algorithm\u2020 to the training',
  'set, separately, to develop one',
  'predictive equation for each.',
  sep=' \n')

step3 = paste(
  'Apply each predictive equation',
  'from Step 2, separately, to the',
  'test set to create one set of',
  'predictions for each algorithm',
  'that can be evaluated in Step 4.',
  sep=' \n')

step4 = paste( 
  'Compute and record the',
  'calibration, discrimination,',
  'and Brier score for each',
  'set of predictions from',
  'Step 3, separately.',
  sep=' \n')

step5 = paste( 
  'Repeat Steps 1-4',
  '100+ times to',
  'internally validate', 
  'each algorithm.',
  sep=' \n')

stepf = paste( 
  'Based on internally validated calibration, discrimination, and Brier score estimates,',
  'select one algorithm to develop predictive equations using the full set of derivation data.',
  sep=' \n')


rx=list(super=1/3, big=1/6, small=1/15)
ry=list(super=.15, big=.08, small=0.03)

bump_coef <- 6/5
txt_size=1.1

xmid = mean(
  c(
    xvals[1]+rx$big,
    xvals[2]-rx$super
  )
)

openplotmat()


# Arrows ------------------------------------------------------------------

straightarrow(
  from = c(xvals[1]+rx$big,yvals[1]+0.45*ry$super*bump_coef),
  to = c(xvals[2],yvals[1]+0.45*ry$super*bump_coef),
  arr.pos=0.43
)

straightarrow(
  from = c(xvals[2],yvals[1]+2.2*ry$small),
  to = c(xvals[2],yvals[2]+0.13),
  arr.pos = 1
)

straightarrow(
  from = c(xvals[2],yvals[2]),
  to = c(xvals[2],yvals[3]-2.2*ry$small+0.13),
  arr.pos = 1
)

bentarrow(
  from = c(xmid,yvals[1]-0.45*ry$super*bump_coef),
  to = c(xvals[2],yvals[2]),
  path = 'V',
  arr.pos=0.41
)

treearrow(
  from = c(xvals[1]+rx$small,yvals[1]),
  to = c(xmid-rx$small,yvals[1]+0.45*ry$super*bump_coef),
  path = 'V',
  arr.pos=0.97
)

treearrow(
  from = c(xvals[1]+rx$small,yvals[1]),
  to = c(xmid-rx$small,yvals[1]-0.45*ry$super*bump_coef),
  path = 'V',
  arr.pos=0.97
)

straightarrow(
  from = c(xvals[2]-rx$big,yvals[3]-2.2*ry$small),
  to = c(xvals[1]+rx$big*0.65, yvals[3]-2.2*ry$small),
  arr.pos = 1
)

straightarrow(
  from = c(xvals[1],yvals[3]+ry$small),
  to = c(xvals[1],yvals[1]-0.20),
  arr.pos = 1
)

straightarrow(
  from = c(xvals[1],yvals[3]-5*ry$small),
  to = c(xvals[1],yvals[4]+ry$small),
  arr.pos = 1
)


# Step 1 ------------------------------------------------------------------

textempty(
  mid = c(xvals[1],yvals[1]+0.15), 
  lab = 'STEP 1', 
  font = 2, 
  cex = txt_size)

textempty(
  mid = c(xvals[1],yvals[1]-0.15), 
  lab = 'Derivation \ndata', 
  font = 2, 
  cex = txt_size)

textrect(
  mid = c(xvals[1],yvals[1]), 
  radx = rx$small*1.20, 
  rady = 0.80*ry$super, 
  lab = step1, 
  font = 1,
  cex = txt_size,
  shadow.size = 1e-10,
  box.col='white')

textrect(
  mid = c(xmid,yvals[1]+0.45*ry$super*bump_coef), 
  radx = rx$small, 
  rady = 0.90*ry$super/2, 
  lab = "Training \nset", 
  font = 2,
  cex = txt_size,
  shadow.size = 1e-10,
  box.col=trn_col)

textrect(
  mid = c(xmid,yvals[1]-0.45*ry$super*bump_coef), 
  radx = rx$small, 
  rady = 0.90*ry$super/2, 
  lab = "Test \nset", 
  font = 2,
  cex = txt_size,
  shadow.size = 1e-10,
  box.col=tst_col)


# Step 2 ------------------------------------------------------------------

textempty(
  mid = c(xvals[2],yvals[1]+2.2*ry$small+0.10), 
  lab = 'STEP 2', 
  font = 2, 
  cex = txt_size)

textrect(
  mid = c(xvals[2],yvals[1]+2.2*ry$small), 
  radx = rx$big, 
  rady = ry$big, 
  lab = step2, 
  cex = txt_size,
  shadow.size = 1e-10,
  box.col=trn_col)


# Step 3 ------------------------------------------------------------------

textempty(
  mid = c(xvals[2],yvals[2]+0.10), 
  lab = 'STEP 3', 
  font = 2, 
  cex = txt_size)

textrect(
  mid = c(xvals[2],yvals[2]), 
  radx = rx$big, 
  rady = ry$big, 
  lab = step3, 
  cex = txt_size,
  shadow.size = 1e-10,
  box.col=tst_col)

# Step 4 ------------------------------------------------------------------

textempty(
  mid = c(xvals[2],yvals[3]-2.2*ry$small+0.10), 
  lab = 'STEP 4', 
  font = 2, 
  cex = txt_size)

textrect(
  mid = c(xvals[2],yvals[3]-2.2*ry$small), 
  radx = rx$big, 
  rady = ry$big, 
  lab = step4, 
  cex = txt_size,
  shadow.size = 1e-10,
  box.col='mistyrose')

# Step 5 ------------------------------------------------------------------

textempty(
  mid = c(xvals[1],yvals[3]), 
  lab = 'STEP 5', 
  font = 2, 
  cex = txt_size)

textempty(
  mid = c(xvals[1],yvals[3]-0.025*3), 
  lab = step5, 
  cex = txt_size)

# Final step --------------------------------------------------------------

textempty(
  mid = c(xvals[1],yvals[4]), 
  lab = 'STEP 6', 
  font = 2, 
  cex = txt_size)

textempty(
  mid = c(xvals[1]+0.05, yvals[4]+0.025), 
  lab = stepf, 
  adj = c(0,1),
  cex = txt_size)

```

---
background-image: url(figs/kfold_cv.png)
background-position: 50% 50%
background-size: 100%

---
layout: true
background-image: url(hex_stickers/PNG/rsample.png)
background-position: 95% 2.5%
background-size: 13%

# Computers and k-fold CV

---

Remember how we selected 9 variables for our first stepwise model?

```{r, eval = FALSE, echo = TRUE}

# fit stepwise model
step_mdl <- stepAIC(
  object = coxph(Surv(time, status) ~ 1, data = .derivation),
  scope = as.formula(full),
  direction = 'both',
  steps = 9,
  trace = 0
)

# Extract the formula that was identified 
frm_3 <- step_mdl$formula

```


---


**Question** How long did that take?

- There are ~530 candidate predictor variables, so we fit ~530 models in each step. (Why?)

- Suppose it takes about 0.11 seconds to fit each model.

- $\rightarrow$ it takes roughly 58 seconds (~1 minute) to complete one step.

- $\rightarrow$ It takes roughly 530 minutes (~9 hours) to complete 530 steps. 

---

**Question** How long would it take to find the best step number using 10-fold CV?

- Divide the derivation data into 10 folds (~1 second)

- Run through all the steps using folds 1-9 as training data, and validating on fold 10 (~ 9 hours)

- Repeat 9 more times validating on folds 9, 8, ..., and 1 (~ 81 hours)

**Answer** About 90 hours, which is almost 4 days.

--

**What if we could do this in under 5 minutes?**

---
layout: true
background-image: url(figs/esl.jpg)
background-position: 96% 4%
background-size: 18%

# Elastic net regression

---

### What is it?

An extension of linear regression that penalizes regression solutions with larger coefficients. Shrinking coefficients to zero reduces the variance of the model and increases the bias.

--

### Why use it?

- Variable selection is completed during the fitting process

- $N < p$ is no problem (N = number of rows, p = number of columns)

- The `glmnet` package is **fast** and fits all kinds of elastic net models. 

---

**How to use it**

The `glmnet` R package is **fast** but not intuitive.

- Data need to be coerced into a matrix with one-hot encoded categorical columns. 

```{r, echo = TRUE}

library(xgboost.surv) # for cat_yyy functions

train_x <- .derivation %>% 
  select(-c(time, status)) %>% 
  cat_spread() %>% 
  as.matrix()

train_y <- .derivation %>% 
  select(time, status) %>% 
  as.matrix()

test_x <- .validation %>% 
  select(-c(time, status)) %>% 
  cat_transfer(.derivation) %>% 
  cat_spread() %>% 
  as.matrix()

```

---

**How to use it**

The `glmnet` R package is **fast** but not intuitive.

- A parameter called `alpha` needs to be specified explicitly. Another parameter called `lambda` is determined using cross-validation. 

```{r, echo = TRUE}

library(glmnet)

start <- Sys.time()
net_cv <- cv.glmnet(
  x = train_x, 
  y = train_y, 
  family = 'cox', 
  alpha = 0.10
)
stop <- Sys.time()

print(stop - start)


```

---

**How to use it**

The `glmnet` R package is **fast** but not intuitive.

- `plot(net_cv)` require a lot of explanation.


```{r}

plot(net_cv)

```


---

**How to use it**

The `glmnet` R package is **fast** but not intuitive.

- Computing predicted survival probability is done using `c060`.

- The authors of `c060` are still developing the functions to do this. 

```{r, echo = TRUE}

net_prd  <- c060:::fit.glmnet(
  response = train_y, 
  x = train_x, 
  family = 'cox',
  alpha = 0.10,
  cplx = net_cv$lambda.min
) %>% 
  c060:::predictProb.glmnet(
    x = test_x,
    times = btimes,
    response = train_y,
    complexity = net_cv$lambda.min
  )

```

---

The `glmnet` R package is **fast** but not intuitive.

- But it is worth it!

```{r, echo = TRUE}

net_ibs <- ibs_scale(net_prd, newdata = .validation, btimes)

ibs_vals <- c(ibs_vals,
  'Elastic regression (pre-implant + week 1)' = net_ibs)

```

```{r, echo = FALSE}

cap <- "Table 3: Validation of four models using 2016-2017 INTERMACS data"

enframe(ibs_vals) %>% 
  mutate(perc_impr = round(100 * (value / value[1] - 1))) %>% 
  kable(
    caption = cap,
    digits = 3,
    col.names = c('Model', 'Scaled Brier', "% Improvement")
  ) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE)


```


